/**** Start of imports. If edited, may not auto-convert in the playground. ****/
var greater_manch = 
    /* color: #ffc82d */
    /* shown: false */
    /* displayProperties: [
      {
        "type": "rectangle"
      }
    ] */
    ee.Geometry.Polygon(
        [[[-71.5465120994114, 43.03752397681783],
          [-71.5465120994114, 42.90362882283206],
          [-71.36798426738015, 42.90362882283206],
          [-71.36798426738015, 43.03752397681783]]], null, false),
    classparams = {"opacity":1,"bands":["classification"],"min":1,"max":6,"palette":["33a02c","b2df8a","d20606","6b6687","ffeca5","2b32ff"]},
    tree_equity_nh = ee.FeatureCollection("users/gsmarshall/urban_greenspace/tree_equity_nh"),
    health_indicators_ne = ee.FeatureCollection("users/gsmarshall/urban_greenspace/ne_health_indicators"),
    priority_indicators_places = ee.FeatureCollection("users/gsmarshall/urban_greenspace/ne_indicators_places"),
    trainingpts = ee.FeatureCollection("users/gsmarshall/urban_greenspace/manch_training_pts");
/***** End of imports. If edited, may not auto-convert in the playground. *****/

// *************************** Sandbox **********************
var naip = ee.ImageCollection('USDA/NAIP/DOQQ')
                  .filter(ee.Filter.date('2017-01-01', '2018-12-31'));
var trueColor = naip.select(['R', 'G', 'B']);
var trueColorVis = {
  min: 0.0,
  max: 255.0,
};
Map.centerObject(greater_manch, 17);
Map.addLayer(trueColor, trueColorVis, 'True Color', 0);
 
var naip_manch = ee.ImageCollection('USDA/NAIP/DOQQ').filter(ee.Filter.bounds(greater_manch)).sort('system:time_start', false).first();

var manch_true = naip_manch.select(['R', 'G', 'B']);


// ************************* Composite tiles together **************************
{
// forms a composite image based on several measures from all images in the collection - not sure how these composites will figure in the
// classification but we'll keep them for now
// var composite = naip_4band.reduce(ee.Reducer.median())
//               .addBands(naip_4band.reduce(ee.Reducer.mean()))   // include a mean reducer
//               .addBands(naip_4band.reduce(ee.Reducer.percentile([20])))// include a 20th percentile reducer
//               .addBands(naip_4band.reduce(ee.Reducer.max()))// include a standard deviation reducer
//               .float();
              
// print('composite', composite);

var visParamsMax = {
  bands: ['N_max', 'R_max', 'G_max'],
  min: 0,
  max: 255
};

// Map.addLayer(composite, visParamsMed, 'composite', 0);
}

// ************************* filter by band availability **********************

// filter by images with 4 bands and calculates NDVI
// returns null if image has less than 4 bands, returns image plus ndvi band for valid 4 band images
var band_filter = function(image){
  return ee.Algorithms.If(image.bandNames().length().eq(4), image.addBands(image.normalizedDifference(['N', 'R']).rename('NDVI')), null);
};


// returns composite image of all 4-band naip tiles within the study area
var preprocess = function(study_area){
  //buffer_dist = manchester.bounds().coordinates();
  
  // mapping over featurecollection is slower than filtering, but I haven't been able to get filtering by bands to work
  var naip_4band = ee.ImageCollection('USDA/NAIP/DOQQ').filterBounds(study_area).map(band_filter, true);

  // forms a composite image based on several measures from all images in the collection - not sure how these composites will figure in the
  // classification but we'll keep them for now
  var composite = naip_4band.reduce(ee.Reducer.max())
                .addBands(naip_4band.reduce(ee.Reducer.mean()))   // include a mean reducer
                .addBands(naip_4band.reduce(ee.Reducer.percentile([20])))// include a 20th percentile reducer
                .addBands(naip_4band.reduce(ee.Reducer.stdDev()))// include a standard deviation reducer
                .float();
                
  return composite.clip(study_area);
};

var composite2 = preprocess(greater_manch);
print(composite2);
Map.addLayer(composite2, visParamsMax, 'composite2');


// **************************** Classification ************************
{
// classification function with EE random forest classifier
var addclass = function(classifimage, training_pts){
            

  // parameters for a classifier
  var classifier = ee.Classifier.smileRandomForest({
              numberOfTrees: 300,
              //variablesPerSplit: 0,
              minLeafPopulation: 1,
              bagFraction: 0.5,
              //outOfBagMode: true,
              seed: 0
                  });
                  


  // Trained with 70% of our data.
  var trainedClassifier = classifier.train(training, 'Class', bands);
  
  // Print the confusion matrix.
  var confusionMatrix = trainedClassifier.confusionMatrix();
  // print('Confusion Matrix', confusionMatrix);
  // print('Validation overall accuracy: ', confusionMatrix.accuracy());

  // Return the classified image
  return classifimage.select(bands).classify(trainedClassifier);
};

var bands = composite2.bandNames();
Export.image.toAsset({
  image: composite2,
  description: "manch_composite",
  assetId: "urban_greenspace/manch_composite",
  region: greater_manch,
  scale: 1,
  maxPixels: 1e11
  });

// Collecting values of the pixels that correspond to our manualy collected
// training points
var training = composite2.select(bands).sampleRegions({
          collection: trainingpts,
          properties: ['Class'],
          scale: 1,
          geometries: true
          });

// Add a random field so that the points can be split for training and validation
var withRandom = training.randomColumn('random');

var split = 0.7;  // 70% training, 30% testing.
var trainingPartition = withRandom.filter(ee.Filter.lt('random', split));
var testingPartition = withRandom.filter(ee.Filter.gte('random', split));
// print(testingPartition, trainingPartition);

// // Export validation points
// Export.table.toAsset({
//   collection:testingPartition,
//   description:'validation_pts',
//   assetId:'greenspace_manch_validation'
// });

// Export.table.toAsset({
//   collection:trainingPartition,
//   description:'training_pts',
//   assetId:'greenspace_manch_training'
// });


// Classify the statistics based image
var classified = addclass(composite2, trainingPartition);

Map.addLayer(classified, classparams,'classified',0);
// print('classified image', classified);


// //Export the image
// Export.image.toAsset({
//   image: classified,
//   description: 'Nakuru_class',
//   scale: 30,
//   region: trainingpts,
//   maxPixels: 1e13
// });


}

// *************************** accuracy assessment ***********************************

// Remap supervised classification to boolean image - green vs else
var green = classified.remap([1,2,3,4,5,6], [1,0,0,0,0,0]);

// Remap validation points
var boolean_pts = testingPartition.remap([1,2,3,4,5,6], [1,0,0,0,0,0], 'Class');

// Add layer to the map to inspect
Map.addLayer(green, {palette: ['#000000', '#00FFFF']}, 'woodlots',0);
Map.addLayer(boolean_pts, {color: '#00FF00'}, 'validation pts',0);

// reduce regions captures classified value (as the 'sum' reducer) so that we can compare to the 
// "true" value stored in the Class variable
var classMatrix = green.reduceRegions(boolean_pts, ee.Reducer.sum(), 1);
var lcMatrix = classified.reduceRegions(testingPartition, ee.Reducer.sum(), 1);

Export.table.toDrive(classMatrix,
"class_confusion_matrix",
"class_confusion_matrix");

Export.table.toDrive(lcMatrix,
"landcover_confusion_matrix",
"landcover_confusion_matrix");


// ***************************** census analysis *******************************

// class structure: probably make each city area an object, with members for region, max and min scores, etc
//print('priority:', priority_indicators_places.aggregate_count('GEOID'));

// ************************************ join health data **************************************
// print('health_data:', health_data);
// need to join health data to census data - first 11 characters of geoid represent tract id
// first extract tract fips code from block group geoid
var addTractID = function(feature){
  var tractID = feature.getString('GEOID').slice(0, 11);
  return feature.set({tract_id: tractID});
};

var priority_places_health = priority_indicators_places.map(addTractID);

var health_select = health_indicators_ne.select(['tractfips','phlth_crud', 'mhlth_crud', 'casthma_cr', 'chd_crudep'], ['tractfips', 'phys_hlth', 'ment_hlth', 'asthma', 'chd']);
var filter = ee.Filter.equals({leftField: 'tract_id', rightField: 'tractfips'});
var health_indicators = ee.Join.inner('primary', 'secondary').apply(priority_places_health, health_select, filter);

// trying to preserve features without matches in health data, but dealing with nulls is very difficult
// ultimately, probably not worth it since keeping those features would mean that their score is calculated with incomplete data
// var priority_health = priority.map(addTractID);
// var health_select = health_data.select(['tractfips','phlth_crud', 'mhlth_crud', 'casthma_cr', 'chd_crudep'], ['tractfips', 'phys_hlth', 'ment_hlth', 'asthma', 'chd']);
// var filter = ee.Filter.equals({leftField: 'tract_id', rightField: 'tractfips'});
// var health_indicators = ee.Join.saveAll({matchesKey: 'primary', outer: true}).apply(priority_health, health_select, filter);


// combine columns from joined feature into a single feature
var cleanJoin = function(feature){
  return ee.Feature(feature.get('primary')).copyProperties(feature.get('secondary'));
};

var priority_places_health = health_indicators.map(cleanJoin);
// check feature counts
// print('health_indicators', health_indicators.aggregate_count('GEOID'));
//print('priority_places_health', priority_places_health.aggregate_count('GEOID'));

      
// ********************* split input feature collection by place area ******************
// check feature counts
// print('pre analysis: priority_indicators_places', priority_indicators_places.aggregate_count('GEOID')); // 6488 block grps
// print('pre analysis places', priority_indicators_places.aggregate_array('p_GEOID').distinct()); // 446 places


// create list of unique place names - should be 446 place areas in study region of NE + NY
// file starts off with ~773 features, but it seems there are some duplicates - will check later
var place_names = priority_places_health.aggregate_array('p_GEOID').distinct();
print("place_names", place_names);

var test_list = ee.List(['2516530']);

// construct dictionary of place names
var place_dict = ee.Dictionary.fromLists(place_names, ee.List.repeat(0, priority_places_health.aggregate_array('p_GEOID').distinct().length()));

var place_collection = ee.Dictionary();

// mapped over featurecollection
// given a metro area name and a feature, returns the input feature if its value for metro_name matches the 
// given input metro name, and returns null otherwise
var filterPlaces = function(this_place_name){
  var wrap = function(feature){
    return ee.Algorithms.If(ee.String(this_place_name).match(feature.getString('p_GEOID')).size().gt(0), feature, null);
  };
  return wrap;
};

// mapped over dictionary of metro names
// for each name, maps another function over the input feature collection and selects features to put into collection for each name
var addPlaces = function(key, value){
  var collection = priority_places_health.map(filterPlaces(key), true);
  collection = collection.set({place_id: key});
  // add featurecollection to dictionary
  return collection;
};

// the same as above, but mapped over list of metro names so the whole thing can be converted to a featurecollection
// for each name, maps another function over the input feature collection and selects features to put into collection for each name
var addPlacesList = function(element){
  var collection = priority_places_health.map(filterPlaces(element), true);
  collection = collection.set({place_id: element});
  // add featurecollection to list
  return collection;
};

place_collection = place_dict.map(addPlaces);
var place_list = place_names.map(addPlacesList);
var test_places = test_list.map(addPlacesList);
print("place list", place_list);
print("place list", test_places);


// *********************** add census priority indicators ************************
// need to do all the field calculations feature by feature and map over the collection
var addLowIncomePct = function(feature){
    return feature.set({low_income: feature.getNumber('C17002_001').subtract(feature.getNumber('C17002_008')).divide(feature.getNumber('C17002_001'))});
};

var addNonWhitePct = function(feature){
  return feature.set({nonwhite: feature.getNumber('B03002_001').subtract(feature.getNumber('B03002_003')).divide(feature.getNumber('B03002_001'))});
};


var addUnemploymentPct = function(feature){
  return feature.set({unemployed_pct: feature.getNumber('B23025_005').divide(feature.getNumber('B23025_002'))});
};

var addSeniorsPct = function(feature){
  // separate out the sums to make it a bit easier to read
  var seniorsM = feature.getNumber('B01001_020').add(feature.getNumber('B01001_021'))
    .add(feature.getNumber('B01001_022'))
    .add(feature.getNumber('B01001_023'))
    .add(feature.getNumber('B01001_024'))
    .add(feature.getNumber('B01001_025'));
    
  var seniorsW = feature.getNumber('B01001_044').add(feature.getNumber('B01001_045'))
    .add(feature.getNumber('B01001_046'))
    .add(feature.getNumber('B01001_047'))
    .add(feature.getNumber('B01001_048'))
    .add(feature.getNumber('B01001_049'));

  return feature.set({
    seniors_pct: seniorsM.add(seniorsW).divide(feature.getNumber('B01001_001'))
  });
};

var addChildPct = function(feature){
  // separate out the sums to make it a bit easier to read
  var childM = feature.getNumber('B01001_003').add(feature.getNumber('B01001_004'))
    .add(feature.getNumber('B01001_005'))
    .add(feature.getNumber('B01001_006'));
    
  var childW = feature.getNumber('B01001_027').add(feature.getNumber('B01001_028'))
    .add(feature.getNumber('B01001_029'))
    .add(feature.getNumber('B01001_030'));

  return feature.set({
    child_pct: childM.add(childW).divide(feature.getNumber('B01001_001'))
  });
};

// add age variables - percent seniors, percent children, dependency ratio
var addDepRatio = function(feature){
  // total population
  var pop = feature.getNumber('B01001_001');
  
  // separate out the sums to make it a bit easier to read
  var seniorsM = feature.getNumber('B01001_020').add(feature.getNumber('B01001_021'))
    .add(feature.getNumber('B01001_022'))
    .add(feature.getNumber('B01001_023'))
    .add(feature.getNumber('B01001_024'))
    .add(feature.getNumber('B01001_025'));
    
  var seniorsW = feature.getNumber('B01001_044').add(feature.getNumber('B01001_045'))
    .add(feature.getNumber('B01001_046'))
    .add(feature.getNumber('B01001_047'))
    .add(feature.getNumber('B01001_048'))
    .add(feature.getNumber('B01001_049'));
  // total number of seniors
  var seniors = seniorsM.add(seniorsW);
    
  // separate out the sums to make it a bit easier to read
  var childM = feature.getNumber('B01001_003').add(feature.getNumber('B01001_004'))
    .add(feature.getNumber('B01001_005'))
    .add(feature.getNumber('B01001_006'));
    
  var childW = feature.getNumber('B01001_027').add(feature.getNumber('B01001_028'))
    .add(feature.getNumber('B01001_029'))
    .add(feature.getNumber('B01001_030'));
  // total number of children
  var children = childM.add(childW);
  
  return feature.set({
    seniors_pct: seniors.divide(pop),
    child_pct: children.divide(pop),
    // dependency ratio = (children + seniors)/(pop age 18-64) = (children + seniors)/(total pop - (children + seniors))
    dep_ratio: children.add(seniors).divide(pop.subtract(children.add(seniors)))});
};

// map all functions over collection
// this could potentially be run faster by combining these functions so I only have to do one
// map() operation, but compared to the computational work of calculating canopy cover it
// doesn't really make a difference
//var priority2 = priority.map(addLowIncomePct).map(addNonWhitePct).map(addUnemploymentPct).map(addDepRatio);

// *************************** calculate tree cover and gap *********************************************
// do zonal stats by sample regions -> field calculator
// specify projection as NAD83/New Hampshire
// ideally, we might change the projection based on what state the place is in
// this would be very doable, but due to time constraints was not implemented here
// the NH projection, which is based on a transverse Mercator, should be good enough for this analysis
// input: boolean classified tree cover, where 1 = tree, 0 = other
// var tree_cover = green.reduceRegions({
//   collection: priority2, 
//   reducer: ee.Reducer.sum(), 
//   scale: 4, // scale of 4 runs reasonably
//   crs: 'EPSG:32110', 
//   tileScale: 4 // tileScale of 4 with scale of 2 runs, but very slowly
// });
//print('tree_cover:', tree_cover);


// canopy goal for all areas in this analysis is 0.4, so the goal values are constant and could be hardcoded, but for the 
// sake of clarity and consistency with TES workflow it is treated as a constant that could change in different instances of the analysis
var canopy_goal = 0.4;
var pixel_area = 16;

var setGap = function(feature){
  // compute existing canopy cover
  var canopy = ee.Feature(feature).getNumber('sum').multiply(pixel_area);
  var est_coverage = canopy.divide(ee.Feature(feature).area());
  
  // compute canopy cover goal
  var pop = feature.getNumber('B01001_001');
  var density = pop.divide(ee.Feature(feature).area().divide(1000000)); // convert area from m^2 to km^2
  var goal = 1.2 * canopy_goal;
  // set canopy cover goal - values are from tree equity score methodology
  // using ee.algorithm.if because logical operators don't work reliably with EE server side parallelization
  goal = ee.Algorithms.If(density.gt(2000), 1.0 * canopy_goal, goal);
  goal = ee.Algorithms.If(density.gt(4000), 0.8 * canopy_goal, goal);
  goal = ee.Algorithms.If(density.gt(8000), 0.5 * canopy_goal, goal);

  var gap = ee.Number(goal).subtract(est_coverage);
  // set gap to 0 if it is negative
  gap = ee.Algorithms.If(gap.lt(0), 0.0, gap);
  
  return feature.set({pop_density: density, est_coverage: est_coverage, goal: goal, gap: gap});
};


// var tree_gap = tree_cover.map(setGap);


// *************************** combine priority indicators and calculate equity score *************************
// just need to add health indicators to this section: normalize and average to create composite health score, then average with other indicators
// calculate max and min citywide for each indicator
// var gap_max = tree_gap.aggregate_max('gap');
// gap_max = ee.Algorithms.If(ee.Number(gap_max).lt(0), 0.0, gap_max);
// var dep_max = tree_gap.aggregate_max('dep_ratio');
// var dep_min = tree_gap.aggregate_min('dep_ratio');
// var unemployment_max = tree_gap.aggregate_max('unemployed_pct');
// var unemployment_min = tree_gap.aggregate_min('unemployed_pct');
// var nonwhite_max = tree_gap.aggregate_max('nonwhite');
// var nonwhite_min = tree_gap.aggregate_min('nonwhite');
// var low_income_max = tree_gap.aggregate_max('low_income');
// var low_income_min = tree_gap.aggregate_min('low_income');

// var phys_max = tree_gap.aggregate_max('phys_hlth');
// var phys_min = tree_gap.aggregate_min('phys_hlth');
// var ment_max = tree_gap.aggregate_max('ment_hlth');
// var ment_min = tree_gap.aggregate_min('ment_hlth');
// var asthma_max = tree_gap.aggregate_max('asthma');
// var asthma_min = tree_gap.aggregate_min('asthma');
// var chd_max = tree_gap.aggregate_max('chd');
// var chd_min = tree_gap.aggregate_min('chd');

// helper function to normalize a score value between its min and max
var normalize = function(x, min, max){
  return ee.Number(x).subtract(ee.Number(min)).divide(ee.Number(max).subtract(ee.Number(min)));
};



// print(equityScore(tree_gap.first()));
// var tes_manch = tree_gap.map(equityScore);
// print('final tes data: ', tes_manch);

var equity_vis = {
  min: 50,
  max: 100,
  palette: ['#030303', '#edf8fb','#ccece6','#99d8c9','#66c2a4','#41ae76','#238b45','#005824'],
  opacity: 0.7
};


// ********************** implement analysis for place region *********************
// input: feature collection representing a single metropolitan area with census data and health indicators
// output: feature collection with equity scores for each block group
var placeAnalysis = function(feature_collection){
  // Preprocessing and image classification
  var study_area = ee.FeatureCollection(feature_collection).geometry();
  // print("image size", study_area.area());//.bounds(); // get study area from bounding box of input feature collection
  var composite_image = preprocess(study_area);

  // Classify the statistics based image - in the final code trainingPartition should be something like a static class member
  var classified = addclass(composite_image, trainingPartition);
  // Remap supervised classification to boolean image - green vs else
  var green = classified.remap([1,2,3,4,5,6], [1,0,0,0,0,0]);

  // Census analysis
  // calculate priority indicators from raw data
  var priority_census = ee.FeatureCollection(feature_collection).map(addLowIncomePct).map(addNonWhitePct).map(addUnemploymentPct).map(addDepRatio);
  // print("priority_census", priority_census);
  
  // calculate tree cover area
  // input: boolean classified tree cover, where 1 = tree, 0 = other
  var tree_cover = green.reduceRegions({
    collection: priority_census,
    reducer: ee.Reducer.sum(),
    scale: 4, // scale of 4 runs reasonably
    crs: 'EPSG:32110',   // specify projection as NAD83/New Hampshire - need to set as object member to adjust for different regions
    tileScale: 4 // tileScale of 4 with scale of 2 runs, but very slowly
  });

  var tree_gap = tree_cover.map(setGap);
  // print("tree_gap", tree_gap);

  // calculate max and min citywide (the whole feature collection) for each indicator
  var gap_max = tree_gap.aggregate_max('gap');
  gap_max = ee.Algorithms.If(ee.Number(gap_max).lt(0), 0.0, gap_max);
  var dep_max = tree_gap.aggregate_max('dep_ratio');
  var dep_min = tree_gap.aggregate_min('dep_ratio');
  var unemployment_max = tree_gap.aggregate_max('unemployed_pct');
  var unemployment_min = tree_gap.aggregate_min('unemployed_pct');
  var nonwhite_max = tree_gap.aggregate_max('nonwhite');
  var nonwhite_min = tree_gap.aggregate_min('nonwhite');
  var low_income_max = tree_gap.aggregate_max('low_income');
  var low_income_min = tree_gap.aggregate_min('low_income');
  
  var phys_max = tree_gap.aggregate_max('phys_hlth');
  var phys_min = tree_gap.aggregate_min('phys_hlth');
  var ment_max = tree_gap.aggregate_max('ment_hlth');
  var ment_min = tree_gap.aggregate_min('ment_hlth');
  var asthma_max = tree_gap.aggregate_max('asthma');
  var asthma_min = tree_gap.aggregate_min('asthma');
  var chd_max = tree_gap.aggregate_max('chd');
  var chd_min = tree_gap.aggregate_min('chd');
  
  // input: feature with all indicators and canopy gap calcuated
  // output: final tree equity score
  var equityScore = function(feature){
    // normalize gap score
    var gap_norm = (feature.getNumber('gap').divide(gap_max));//.multiply(100);
  
    // normalize health indicators
    var phys_norm = normalize(feature.getNumber('phys_hlth'), phys_min, phys_max);
    var ment_norm = normalize(feature.getNumber('ment_hlth'), ment_min, ment_max);
    var asthma_norm = normalize(feature.getNumber('asthma'), asthma_min, asthma_max);
    var chd_norm = normalize(feature.getNumber('chd'), chd_min, chd_max);
    // average together to make composite health score
    var health_norm = phys_norm.add(ment_norm).add(asthma_norm).add(chd_norm).divide(4);
    
    
    // normalize priority indicators
    var dep_norm = normalize(feature.getNumber('dep_ratio'), dep_min, dep_max);
    var unemployment_norm = normalize(feature.getNumber('unemployed_pct'), unemployment_min, unemployment_max);
    var nonwhite_norm = normalize(feature.getNumber('nonwhite'), nonwhite_min, nonwhite_max);
    var low_income_norm = normalize(feature.getNumber('low_income'), low_income_min, low_income_max);
    // combine priority indicators and gap score
    var priority = dep_norm.add(unemployment_norm).add(nonwhite_norm).add(low_income_norm).add(health_norm).divide(4);
    var tes = ee.Number(100).multiply(ee.Number(1).subtract(gap_norm.multiply(priority)));
    
    return feature.set({health_norm: health_norm, priority: priority, tes: tes});
  };
  tree_gap = tree_gap.set({place_id: ee.FeatureCollection(feature_collection).getString('place_id')});
  return tree_gap.map(equityScore);

};

var manch = place_collection.get("3345140");
print("manch", manch);

  // // Preprocessing and image classification
  // var study_area = ee.FeatureCollection(manch).geometry();
  // print("image size", study_area.area());//.bounds(); // get study area from bounding box of input feature collection
  // var composite_image = preprocess(study_area);

  // // Classify the statistics based image - in the final code trainingPartition should be something like a static class member
  // var classified = addclass(composite_image, trainingPartition);
  // // Remap supervised classification to boolean image - green vs else
  // var green = classified.remap([1,2,3,4,5,6], [1,0,0,0,0,0]);

  // // Census analysis
  // // calculate priority indicators from raw data
  // var priority_census = ee.FeatureCollection(manch).map(addLowIncomePct).map(addNonWhitePct).map(addUnemploymentPct).map(addDepRatio);
  // print("priority_census", priority_census);
  
  // // calculate tree cover area
  // // input: boolean classified tree cover, where 1 = tree, 0 = other
  // var tree_cover = green.reduceRegions({
  //   collection: priority_census,
  //   reducer: ee.Reducer.sum(),
  //   scale: 4, // scale of 4 runs reasonably
  //   crs: 'EPSG:32110',   // specify projection as NAD83/New Hampshire - need to set as object member to adjust for different regions
  //   tileScale: 4 // tileScale of 4 with scale of 2 runs, but very slowly
  // });

  // var tree_gap = tree_cover.map(setGap);
  // print("tree_gap", tree_gap);

  // // calculate max and min citywide (the whole feature collection) for each indicator
  // var gap_max = tree_gap.aggregate_max('gap');
  // gap_max = ee.Algorithms.If(ee.Number(gap_max).lt(0), 0.0, gap_max);
  // var dep_max = tree_gap.aggregate_max('dep_ratio');
  // var dep_min = tree_gap.aggregate_min('dep_ratio');
  // var unemployment_max = tree_gap.aggregate_max('unemployed_pct');
  // var unemployment_min = tree_gap.aggregate_min('unemployed_pct');
  // var nonwhite_max = tree_gap.aggregate_max('nonwhite');
  // var nonwhite_min = tree_gap.aggregate_min('nonwhite');
  // var low_income_max = tree_gap.aggregate_max('low_income');
  // var low_income_min = tree_gap.aggregate_min('low_income');
  
  // var phys_max = tree_gap.aggregate_max('phys_hlth');
  // var phys_min = tree_gap.aggregate_min('phys_hlth');
  // var ment_max = tree_gap.aggregate_max('ment_hlth');
  // var ment_min = tree_gap.aggregate_min('ment_hlth');
  // var asthma_max = tree_gap.aggregate_max('asthma');
  // var asthma_min = tree_gap.aggregate_min('asthma');
  // var chd_max = tree_gap.aggregate_max('chd');
  // var chd_min = tree_gap.aggregate_min('chd');

  // var tes_manch2 = tree_gap.map(equityScore);


//var tes_manch2 = placeAnalysis(manch);
// var tes_bos = placeAnalysis(place_collection.get("2507000"));
// print("tes_bos", tes_bos);

var test_tes_places = ee.FeatureCollection(test_places.map(placeAnalysis)).flatten();
print("test_tes_places", test_tes_places);
print("test_tes_place", test_tes_places.get(0));

// var preprocessed_list = ee.FeatureCollection(place_names.map(addPlacesList)).flatten();
// print(preprocessed_list);

//print("tes_manch", tes_manch2);
// Export.table.toAsset({
//   collection: preprocessed_list,
//   description: 'preprocessed_input',
//   assetId: 'place_collection_ne_input'
// });

// Export.table.toDrive({
//   collection: ee.FeatureCollection(place_list.map(placeAnalysis)).flatten(),
//   description: 'tes_calculation',
//   folder: 'CS 701 Urban Green Space',
//   fileNamePrefix: 'place_collection_tes_output',
//   fileFormat: 'GeoJSON'
// });

// seems like when you use paint() twice like this, the lines get colored as the first element of the palette list
// var my_tes_image = ee.Image().byte().paint({
//   featureCollection: tes_manch2,
//   color: 'tes'
// }).paint({
//   featureCollection: tes_manch2,
//   color: '030303',
//   width: 1
// });

var tes_image = ee.Image().byte().paint({
  featureCollection: tree_equity_nh,
  color: 'tes'
}).paint({
  featureCollection: tree_equity_nh,
  color: '030303',
  width: 1
});


// Map.addLayer(my_tes_image, equity_vis, 'My Tree Equity Data');
Map.addLayer(tes_image, equity_vis, 'TES Tree Equity Data');